{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 Dataset Format\n",
    "\n",
    "# This document describes the V2 dataset format. This format is used by the updated Dataloader for increased speed especially on large datasets.\n",
    "\n",
    "# TL:DR\n",
    "files on disk now contain 1000 samples not 1\n",
    "\n",
    "Files on disk are now tensors not numpy arrays\n",
    "\n",
    "Files on disk now have shape [1000, 1, 128, 88] not [128, 88]\n",
    "\n",
    "Datsets now have minimum size of 1000 samples. And total samples must be a multiple of 1000?\n",
    "\n",
    "# CHANGES FROM V1\n",
    "- Instead of each file being saved on disk as a single numpy array, files are now saved in 'bundles' of 1000 samples each. This allows for faster loading of the dataset by reducing load calls from disk by 1000x which was a previous bottleneck.\n",
    "\n",
    "- data is now saved to disk as tensors instead of numpy arrays. removing the need for conversion to tensors in the dataloader.???\n",
    "\n",
    "- Channel dim is already included in the data. This means that the data is now of shape (X, C, Y)????(C, X, Y) instead of (X, Y). Which removes this step from the dataloader.\n",
    "\n",
    "- Sparse??\n",
    "\n",
    "- NPZ support??\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bundles: 100%|\u001b[33m██████████\u001b[0m| 1000/1000 [4:58:28<00:00, 17.91s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%% - User Inputs\n",
    "bundle_size = 1000    # 1K for V2 Spec\n",
    "dataset_full_filepath = r\"N:\\Yr 3 Project Datasets\\RDT 1M\\RDT 1M\\\\Data\\\\\"\n",
    "dataset_output_filepath = r\"A:\\[V2]RDT 1M\\Data\\\\\"\n",
    "\n",
    "#%%\n",
    "import os\n",
    "import numpy as np\n",
    "import torch    \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Append \\Data\\ to the end of both filepaths\n",
    "#dataset_full_filepath = os.path.join(dataset_full_filepath, \"Data\")\n",
    "#dataset_output_filepath = os.path.join(dataset_output_filepath, \"Data\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(dataset_output_filepath):\n",
    "    os.makedirs(dataset_output_filepath)\n",
    "else:\n",
    "    raise Exception(\"Output directory already exists, please delete it before running this script\")\n",
    "\n",
    "# Get a list of all the files in the dataset\n",
    "dataset_files = os.listdir(dataset_full_filepath)\n",
    "\n",
    "# create batches of 'bundle_size' file paths and add each batch to a list\n",
    "file_paths_on_disk = [dataset_files[i:i+bundle_size] for i in range(0, len(dataset_files), bundle_size)]\n",
    "\n",
    "for bundle_idx, batch_of_file_paths_on_disk in enumerate(tqdm(file_paths_on_disk, desc=\"Processing bundles\", colour=\"yellow\")):\n",
    "    \n",
    "    #iterativly load 1000 numpy arrys into one array\n",
    "    data_bundle = np.stack([np.load(dataset_full_filepath + file_path) for file_path in (batch_of_file_paths_on_disk)], axis=0)\n",
    "\n",
    "    # turn to tensor\n",
    "    data_bundle = torch.tensor(data_bundle, dtype=torch.float64)\n",
    "\n",
    "    # add channel dim\n",
    "    data_bundle = data_bundle.unsqueeze(1)\n",
    "\n",
    "    # name file\n",
    "    file_name = f'test_{bundle_idx}.pt'\n",
    "\n",
    "    # save to disk\n",
    "    torch.save(data_bundle, os.path.join(dataset_output_filepath, file_name))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
