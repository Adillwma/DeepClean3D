import numpy as np
import matplotlib.pyplot as plt
import math
import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader,random_split
from torch import nn
import random 
import torch.nn as nn
from Restarting_Build.Calc import conv_calculator


"""
This is barely different to the ConvV1, the only difference is trying to use Conv3d on the data
instead of flattened conv2d data.
"""

"""
All you need to do here is link the first array and the datasets to automate the AE.
"""
# the test and train directories used later:
train_dir = r"C:\Users\maxsc\OneDrive - University of Bristol\3rd Year Physics\Project\Autoencoder\2D 3D simple version\Circular and Spherical Dummy Datasets\Cross Stuff\MultiX - 80%1X - 20%2X - 128x88/"
test_dir = r"C:\Users\maxsc\OneDrive - University of Bristol\3rd Year Physics\Project\Autoencoder\2D 3D simple version\Circular and Spherical Dummy Datasets\Cross Stuff\MultiX - 80%1X - 20%2X - 128x88/"

# load a single array in order to find its dimensions:
single_array = np.load(r"C:\Users\maxsc\OneDrive - University of Bristol\3rd Year Physics\Project\Autoencoder\2D 3D simple version\Circular and Spherical Dummy Datasets\Cross Stuff\MultiX - 80%1X - 20%2X - 128x88\Data\Flat SimpleX-128x88-1 Crosses, No0.npy")
print(np.shape(single_array))
# for conv converter:
conv_type = 0
K = [3,3]
P = [1,1] # (changed later)
S = [2,2]
D = [1,1]
H_in = np.shape(single_array)[0] # (change later)
W_in = np.shape(single_array)[1]
D_in = np.shape(single_array)[2]
O = None

# Calculator here:
# # for first 2 conv layers:
# H_in, W_in and D_in would be given in fc2_input_dim
# padding is initially 1 on top, 1 on bottom and sides for first two layers
P = [1,1,1]
L1 = conv_calculator(conv_type, K, P, S, D, H_in, W_in, D_in, O)
print('N.B. the following dimensions dont include the channels: \n')
print('Dimensions after first layer: ', str(math.floor(L1[0])), 'x', str(math.floor(L1[1])), 'x', str(math.floor(L1[2])))

# need to use math.floor to make sure to round down from .5 values
L2 = conv_calculator(conv_type, K, P, S, D, math.floor(L1[0]), math.floor(L1[1]), math.floor(L1[2]), O)
print('Dimensions after second layer: ', str(math.floor(L2[0])), 'x', str(math.floor(L2[1])), 'x', str(math.floor(L2[2])))


# # for 3rd and final layer padding changed to (0,0,0)
P = [0,0,0]
L3 = conv_calculator(conv_type, K, P, S, D, math.floor(L2[0]), math.floor(L2[1]), math.floor(L2[2]), O)
print('Dimensions after third layer: ', str(math.floor(L3[0])), 'x', str(math.floor(L3[1])), 'x', str(math.floor(L3[2])))


# this is the channels out of the 
channels_out = 32

# this is the convolutional network. Outputs should be 2 - the velocity and the impact point:
class Encoder(nn.Module):
    
    def __init__(self, num_outputs,fc2_input_dim):
        super().__init__()
        
        # the numbers here are the channels
        self.encoder_cnn = nn.Sequential(
            #Convolutional encoder layer 1                 
            nn.Conv3d(1, 8, 3, stride=2, padding=1),       #Input_channels, Output_channels, Kernal_size, Stride, Padding
            nn.ReLU(True),                                 #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false
            #Convolutional encoder layer 2
            nn.Conv3d(8, 16, 3, stride=2, padding=1),
            nn.BatchNorm3d(16),                            #BatchNorm normalises the outputs as a batch? #!!!. argument is 'num_features' (expected input of size)
            nn.ReLU(True),
            #Convolutional encoder layer 3
            nn.Conv3d(16, 32, 3, stride=2, padding=0),
            nn.ReLU(True)
        )
        
        ###Flatten layer
        self.flatten = nn.Flatten(start_dim=1)
        

        ###Linear Encoder Layers
        
        #nn.Linear arguments are: in_features – size of each input sample, out_features – size of each output sample, bias – If set to False, the layer will not learn an additive bias. Default: True
        self.encoder_lin = nn.Sequential(
            #Linear encoder layer 1  
            nn.Linear(math.floor(L3[0]) * math.floor(L3[1]) * channels_out, 128),                   #!!! linear network layer. arguuments are input dimensions/size, output dimensions/size. Takes in data of dimensions 3* 3 *32 and outputs it in 1 dimension of size 128
            # nn.Linear(L3[0] * L3[1] * 32, 128),
            nn.ReLU(True),                                #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false
            #Linear encoder layer 2
            nn.Linear(128, num_outputs)             #Takes in data of 1 dimension with size 128 and outputs it in one dimension of size defined by encoded_space_dim (this is the latent space? the smalle rit is the more comression but thte worse the final fidelity)
        )
    
    # this basically just executes everything weve just defined in dunder init
    def forward(self, x):
        x = self.encoder_cnn(x)                           # Runs convoloutional encoder
        #print(np.shape(x))
        x = self.flatten(x)                               # Flattens data
        #print(np.shape(x))
        x = self.encoder_lin(x)                           # Puts it through linear layers
        return x      
