{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.stats import sem\n",
    "from tabulate import tabulate\n",
    "import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_signal(input_image_batch, signal_points=2, linear=False):\n",
    "    # Take as input a torch tensor in form [batch_size, 1, x_dim, y_dim]]\n",
    "    # Create a copy of the input image batch\n",
    "    image_batch = input_image_batch.clone()\n",
    "\n",
    "    # Flatten the image tensor\n",
    "    flat_batch = image_batch.view(image_batch.size(0), -1)\n",
    "\n",
    "    # Count the number of non-zero values in each image\n",
    "    nz_counts = torch.sum(flat_batch != 0, dim=1)\n",
    "\n",
    "    # Find the indices of the images that have more non-zero values than signal_points\n",
    "    sparse_indices = torch.where(nz_counts > signal_points)[0]\n",
    "\n",
    "    # For each sparse image, randomly select signal_points non-zero values to keep\n",
    "    for idx in sparse_indices:\n",
    "        # Find the indices of the non-zero values in the flattened image\n",
    "        nz_indices = torch.nonzero(flat_batch[idx]).squeeze()\n",
    "\n",
    "        # Randomly select signal_points non-zero values to keep\n",
    "        if linear:\n",
    "            kept_indices = torch.linspace(0, nz_indices.numel() - 1, steps=signal_points).long()\n",
    "        else:\n",
    "            kept_indices = torch.randperm(nz_indices.numel())[:signal_points]\n",
    "\n",
    "        # Zero out all non-selected values\n",
    "        nonkept_indices = nz_indices[~torch.isin(nz_indices, nz_indices[kept_indices])]\n",
    "        flat_batch[idx, nonkept_indices] = 0\n",
    "\n",
    "    # Reshape the flat tensor back into the original shape\n",
    "    output_image_batch = flat_batch.view_as(image_batch)\n",
    "\n",
    "    return output_image_batch\n",
    "\n",
    "def add_noise_points_to_batch_prenorm(input_image_batch, noise_points=100, time_dimension=100):\n",
    "    image_batch = input_image_batch.clone()\n",
    "\n",
    "    if noise_points > 0:\n",
    "        #Find dimensions of input image \n",
    "        x_dim = image_batch.shape[2]\n",
    "        y_dim = image_batch.shape[3]\n",
    "\n",
    "        #For each image in the batch\n",
    "        for image in image_batch:\n",
    "\n",
    "            # Create a list of unique random x and y coordinates\n",
    "            num_pixels = x_dim * y_dim\n",
    "            all_coords = np.arange(num_pixels)\n",
    "            selected_coords = np.random.choice(all_coords, noise_points, replace=False)\n",
    "            x_coords, y_coords = np.unravel_index(selected_coords, (x_dim, y_dim))\n",
    "            \n",
    "            # Iterate through noise_points number of random pixels to noise\n",
    "            for i in range(noise_points):\n",
    "\n",
    "                # Add a random number between recon_threshold and 1 to the pixel \n",
    "                image[0][x_coords[i], y_coords[i]] = np.random.uniform(0, time_dimension)\n",
    "\n",
    "    \n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Data:   0%|          | 0/10000 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Data: 100%|██████████| 10000/10000 [00:54<00:00, 182.81image/s]\n"
     ]
    }
   ],
   "source": [
    "def create_data(path, input_path, signal_points=30, noise_points=100, time_dimension=1000, plot=False):\n",
    "    # if not already exists then create a folder to store the new data in path\\\\Labels\n",
    "    os.makedirs(path + '\\\\Labels\\\\', exist_ok=True)\n",
    "    os.makedirs(path + '\\\\Labels_Sparse\\\\', exist_ok=True)\n",
    "    os.makedirs(path + '\\\\Data\\\\', exist_ok=True)\n",
    "\n",
    "    # load each image in path in turn\n",
    "    for image_path in tqdm(os.listdir(input_path + '\\\\Data\\\\'), desc='Creating Data', unit='image'):\n",
    "        # load npy file\n",
    "        image = np.load(input_path + '\\\\Data\\\\' + image_path)\n",
    "        #turn image into tensor\n",
    "        image_tensor = torch.from_numpy(image)\n",
    "        # add two dimensions to start of tensor\n",
    "        image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)\n",
    "        sparse_output = create_sparse_signal(image_tensor, signal_points)\n",
    "        #sparse_and_resolution_limited = simulate_detector_resolution(sparse_output_batch, x_std_dev_r, y_std_dev_r, tof_std_dev_r)\n",
    "        noised_sparse_reslimited = add_noise_points_to_batch_prenorm(sparse_output, noise_points, time_dimension)\n",
    "        #remove first two dims\n",
    "        noised_sparse_reslimited = noised_sparse_reslimited.squeeze(0).squeeze(0)\n",
    "        # convert to numpy array\n",
    "        noised_sparse_reslimited = noised_sparse_reslimited.numpy()\n",
    "        \n",
    "        if plot:\n",
    "            # plot each image sideby side for comparison\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            ax[0].imshow(image, cmap='gray')\n",
    "            ax[0].set_title('Original Image')\n",
    "            ax[1].imshow(noised_sparse_reslimited, cmap='gray')\n",
    "            ax[1].set_title('Noised, Sparse and Resolution Limited Image')\n",
    "            plt.show()\n",
    "\n",
    "        # save the new image in path\\\\Data\n",
    "        np.save(path + '\\\\Data\\\\' + image_path, noised_sparse_reslimited)\n",
    "        # save the image in path\\\\Labels\n",
    "        np.save(path + '\\\\Labels\\\\' + image_path, image)\n",
    "        # save the image in path\\\\Labels\n",
    "        np.save(path + '\\\\Labels_Sparse\\\\' + image_path, sparse_output.squeeze(0).squeeze(0).numpy())\n",
    "\n",
    " \n",
    "create_data(r\"N:\\\\Yr 3 Project Datasets\\\\PERF VALIDATION SETS\\\\a10K 100N 30S\\\\\", r\"N:\\\\Yr 3 Project Datasets\\\\RDT 10K MOVE\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
