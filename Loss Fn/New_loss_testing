import numpy as np 
import matplotlib.pyplot as plt
import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader,random_split
from torch import nn
import random 
import math
import torch.nn as nn

"""
I made a working loss function that actually runs through the data and forms losses.
This is what i think anyway, it takes so long to compute that it never gets the first batch done.

Options for speeding up the process.
- look into reducing the amount of loops through the data
- identify the actual signal points first in the original and only compute those close to them. otherwise use MSE
- Could only look at square in x and y around it say 10 x 10 and return smallest distance there?
"""
def new_custom_loss(reconstruction, original):
    loss = 0

    # data comes as tensor shape [batch size, 1, 128, 88]
    
    # need to iterate over each image in batch:
    for img in range(reconstruction.shape[0]):
        
        # first find all the 


def custom_loss(reconstruction, original):
    loss = 0
    
    # N.B. images created state they are 128 in x and 88 in y.
    # because of how they are created, when printed to the screen this is 128 DOWN and 88 ACROSS
    # this is because there are 128 rows of 88
    # iterate over each image in batch:
    for img in range(reconstruction.shape[0]):

        # Iterate over each row in the image (usually 128 rows):
        # (i represents y points)
        for i in range(reconstruction.shape[2]):
            
            # iterate over each y point in each row (usually 88 y points per row):
            # (j represents x points)
            for j in range(reconstruction.shape[3]):

                # Calculate distances in x and y axes
                # .shape returns the shape of a pytorch array
                # .arange is the same as range function
                # this returns an array of distances in x (dx)
                dist_x = torch.abs(torch.arange(reconstruction.shape[3]) - j)
                # this returns an array of distances in y (dy)
                dist_y = torch.abs(torch.arange(reconstruction.shape[2]) - i)
                
                # Calculate distance in intensity values (z axis)
                # this is an i x j size tensor
                dist_int = torch.abs(original[img, 0] - reconstruction[img, 0, i, j])
                
                # define empty disance matrix:
                dist = torch.empty([reconstruction.shape[2], reconstruction.shape[3]])

                # Calculate dist matrix, size i x j:
                # for each dist in x
                for x_idx, x in enumerate(dist_x):
                    
                    # for each dist in y
                    for y_idx, y in enumerate(dist_y):
                        
                        # have done y x here as the axes are confusing
                        dist[y_idx,x_idx] = torch.sqrt(x**2 + y**2 + dist_int[y_idx,x_idx]**2)

                        if x == 0 and y == 0:
                            dist[y_idx, x_idx] = 200

                # the smallest distance is the loss:
                smallest_dist = dist.min()

                # .item() extracts single scalar value from a single value tensor
                point_loss = smallest_dist.item()
                loss += point_loss
    
    # Calculate mean loss for the batch
    mean_loss = loss / (reconstruction.shape[2] * reconstruction.shape[3])
    
    return mean_loss