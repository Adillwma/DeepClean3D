{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def Reduced_Dimension_Data_Representations2(encoder, device, test_dataset, plot_or_save=0):\n",
    "    \"\"\"\n",
    "    Display the input data samples as a XXXXX\n",
    "\n",
    "    Parameters:\n",
    "        encoder (torch.nn.Module): The encoder model.\n",
    "        device (str): The device to run the computations on.\n",
    "        test_dataset (TYPE???): The test dataset.\n",
    "        plot_or_save (int, optional): Specifies whether to display the visualization (0) or save it to file (1) or both (2).\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare for error handling\n",
    "        encoded_samples = []\n",
    "\n",
    "        # Ensure that encoder is on the right device\n",
    "        encoder.to(device)\n",
    "        encoder.eval()\n",
    "\n",
    "        # Check if test_dataset is iterable\n",
    "        if not hasattr(test_dataset, '__iter__'):\n",
    "            raise ValueError(\"test_dataset must be iterable\")\n",
    "\n",
    "        for sample in tqdm(test_dataset):\n",
    "            img = sample[0].unsqueeze(0).to(device)\n",
    "            label = sample[1]\n",
    "            # Encode image\n",
    "            with torch.no_grad():\n",
    "                encoded_img = encoder(img)\n",
    "                # Append to list\n",
    "                encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "                encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "                encoded_sample['label'] = label\n",
    "                encoded_samples.append(encoded_sample)\n",
    "\n",
    "        if not encoded_samples:\n",
    "            raise ValueError(\"No encoded samples obtained\")\n",
    "\n",
    "        encoded_samples_df = pd.DataFrame(encoded_samples)\n",
    "\n",
    "        if len(encoded_samples_df) < 2:\n",
    "            raise ValueError(\"Insufficient samples for t-SNE\")\n",
    "\n",
    "        # TSNE of Higher dim\n",
    "        tsne = TSNE(n_components=2)\n",
    "        tsne_results = tsne.fit_transform(encoded_samples_df.drop(['label'], axis=1))\n",
    "\n",
    "        return encoded_samples_df, tsne_results\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "# encoder = your_encoder_model\n",
    "# device = 'cuda' or 'cpu'\n",
    "# test_dataset = your_test_dataset\n",
    "# result_df, tsne_results = Reduced_Dimension_Data_Representations(encoder, device, test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Reduced_Dimension_Data_Representations(encoder, device, test_dataset, plot_or_save=0):\n",
    "    \"\"\"\n",
    "    Display the input data samples as a XXXXX\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "        encoder (torch.nn.Module): The encoder model.\n",
    "        device (str): The device to run the computations on.\n",
    "        test_dataset (TYPE???): The test dataset.\n",
    "        plot_or_save (int, optional): Specifies whether to display the visualization (0) or save it to file (1) or both (2).\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_samples = []\n",
    "        for sample in tqdm(test_dataset):\n",
    "            img = sample[0].unsqueeze(0).to(device)\n",
    "            label = sample[1]\n",
    "            # Encode image\n",
    "            encoder.eval()\n",
    "            with torch.no_grad():\n",
    "                encoded_img = encoder(img)\n",
    "                # Append to list\n",
    "                encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "                encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "                encoded_sample['label'] = label\n",
    "                encoded_samples.append(encoded_sample)\n",
    "        encoded_samples = pd.DataFrame(encoded_samples)\n",
    "\n",
    "        ### TSNE of Higher dim\n",
    "        tsne = TSNE(n_components=2)\n",
    "        tsne_results = tsne.fit_transform(encoded_samples.drop(['label'],axis=1))\n",
    "\n",
    "        return(encoded_samples, tsne_results)\n",
    "\n",
    "    except:\n",
    "        return(None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
