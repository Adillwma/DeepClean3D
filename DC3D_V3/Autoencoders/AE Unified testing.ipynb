{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE LAYER SIZE DEBUG\n",
      "Encoder in torch.Size([1, 1, 1, 3])\n",
      "Encoder Protective Pad out torch.Size([1, 1, 17, 19])\n",
      "Input x size:  torch.Size([1, 1, 17, 19])\n",
      "17 19\n",
      "Resized x to:  torch.Size([1, 1, 24, 19]) adding 7 pixels\n",
      "Resized x to:  torch.Size([1, 1, 24, 24]) adding 5 pixels\n",
      "Encoder Dynamic Input Size Helper out torch.Size([1, 1, 24, 24])\n",
      "Encoder CNN out torch.Size([1, 32, 3, 3])\n",
      "Pre flattened size:  torch.Size([32, 3, 3])\n",
      "Encoder Flatten out torch.Size([1, 288])\n",
      "Encoder Lin out torch.Size([1, 100]) \n",
      "\n",
      "DECODER LAYER SIZE DEBUG\n",
      "Decoder in torch.Size([1, 100])\n",
      "Decoder Lin out torch.Size([1, 288])\n",
      "Decoder Unflatten out torch.Size([1, 32, 3, 3])\n",
      "Decoder CNN out torch.Size([1, 1, 24, 24])\n",
      "Decoder Dynamic Output Size Helper out torch.Size([1, 1, 17, 19])\n",
      "Decoder Protective Pad out torch.Size([1, 1, 1, 3])\n",
      "Decoder out torch.Size([1, 1, 1, 3]) \n",
      "\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Encoder                                  [1, 1, 1, 3]              --\n",
      "├─Sequential: 1-1                        [1, 32, 3, 3]             --\n",
      "│    └─Conv2d: 2-1                       [1, 8, 12, 12]            80\n",
      "│    └─ReLU: 2-2                         [1, 8, 12, 12]            --\n",
      "│    └─Conv2d: 2-3                       [1, 16, 6, 6]             1,168\n",
      "│    └─BatchNorm2d: 2-4                  [1, 16, 6, 6]             32\n",
      "│    └─ReLU: 2-5                         [1, 16, 6, 6]             --\n",
      "│    └─Conv2d: 2-6                       [1, 32, 3, 3]             4,640\n",
      "│    └─ReLU: 2-7                         [1, 32, 3, 3]             --\n",
      "├─Flatten: 1-2                           [1, 288]                  --\n",
      "├─Sequential: 1-3                        [1, 1, 24, 24]            --\n",
      "│    └─ConvTranspose2d: 2-8              [1, 16, 6, 6]             4,624\n",
      "│    └─BatchNorm2d: 2-9                  [1, 16, 6, 6]             32\n",
      "│    └─ReLU: 2-10                        [1, 16, 6, 6]             --\n",
      "│    └─ConvTranspose2d: 2-11             [1, 8, 12, 12]            1,160\n",
      "│    └─BatchNorm2d: 2-12                 [1, 8, 12, 12]            16\n",
      "│    └─ReLU: 2-13                        [1, 8, 12, 12]            --\n",
      "│    └─ConvTranspose2d: 2-14             [1, 1, 24, 24]            73\n",
      "==========================================================================================\n",
      "Total params: 11,825\n",
      "Trainable params: 11,825\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.47\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.10\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "#%% - Dependancies\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#%% - Encoder\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim, encoder_debug=False):\n",
    "        super().__init__()\n",
    "        self.encoder_debug = encoder_debug\n",
    "        self.protection = True\n",
    "        self.dynamic = True\n",
    "        self.dynamic_input_multiple = 8\n",
    "        self.encoded_space_dim = encoded_space_dim\n",
    "\n",
    "        ###Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),       #Input_channels, Output_channels, Kernal_size, Stride, Padding\n",
    "            nn.ReLU(True),                                 #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),      #Input_channels, Output_channels, Kernal_size, Stride, Padding\n",
    "            nn.BatchNorm2d(16),                            #BatchNorm normalises the outputs as a batch? #!!!. argument is 'num_features' (expected input of size)\n",
    "            nn.ReLU(True),                                 #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),     #Input_channels, Output_channels, Kernal_size, Stride, Padding\n",
    "            nn.ReLU(True)                                  #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "        )\n",
    "     \n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),             #Input_channels, Output_channels, Kernal_size, Stride, padding(unused), Output_padding\n",
    "            nn.BatchNorm2d(16),                                                    #BatchNorm normalises the outputs as a batch? #!!!. argument is 'num_features' (expected input of size)\n",
    "            nn.ReLU(True),                                                         #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),   #Input_channels, Output_channels, Kernal_size, Stride, padding, Output_padding\n",
    "            nn.BatchNorm2d(8),                                                     #BatchNorm normalises the outputs as a batch? #!!!. argument is 'num_features' (expected input of size)\n",
    "            nn.ReLU(True),                                                         #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)     #Input_channels, Output_channels, Kernal_size, Stride, padding, Output_padding\n",
    "        )\n",
    "\n",
    "    def set_lin_layers(self, channels, x_size, y_size):\n",
    "\n",
    "        ###Linear Encoder Layers\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(x_size * y_size * channels, 128),                   #!!! linear network layer. arguuments are input dimensions/size, output dimensions/size. Takes in data of dimensions 3* 3 *32 and outputs it in 1 dimension of size 128\n",
    "            nn.ReLU(True),                                #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.Linear(128, self.encoded_space_dim)             #Takes in data of 1 dimension with size 128 and outputs it in one dimension of size defined by encoded_space_dim (this is the latent space? the smalle rit is the more comression but thte worse the final fidelity)\n",
    "        )\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(self.encoded_space_dim, 128),\n",
    "            nn.ReLU(True),                                 #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "            nn.Linear(128, x_size * y_size * channels),\n",
    "            nn.ReLU(True)                                  #ReLU activation function - Activation function determinines if a neuron fires, i.e is the output of the node considered usefull. also allows for backprop. the arg 'True' makes the opperation carry out in-place(changes the values in the input array to the output values rather than making a new one), default would be false\n",
    "        )\n",
    "\n",
    "    def dynamic_input_size_helper(self, x):\n",
    "        # Get the size of the input image x\n",
    "        print(\"Input x size: \", x.size())\n",
    "        size_x = x.size()[2]\n",
    "        size_y = x.size()[3]\n",
    "        print(size_x, size_y)\n",
    "\n",
    "        # check that both dimensions are divisible by self.dynamic_input_multiple in turn, if not then pad the image in that dimension to the nearest multiple of self.dynamic_input_multiple\n",
    "        if size_x % self.dynamic_input_multiple != 0:\n",
    "            self.adding_x_pixels = self.dynamic_input_multiple - size_x % self.dynamic_input_multiple\n",
    "            x = nn.functional.pad(x, (0, 0, 0, self.adding_x_pixels))\n",
    "            print(\"Resized x to: \", x.size(), \"adding\", self.adding_x_pixels, \"pixels\")\n",
    "        else:\n",
    "            self.adding_x_pixels = 0\n",
    "\n",
    "        if size_y % self.dynamic_input_multiple != 0:\n",
    "            self.adding_y_pixels = self.dynamic_input_multiple - size_y % self.dynamic_input_multiple\n",
    "            x = nn.functional.pad(x, (0, self.adding_y_pixels, 0, 0))\n",
    "            print(\"Resized x to: \", x.size(), \"adding\", self.adding_y_pixels, \"pixels\")\n",
    "        else:\n",
    "            self.adding_y_pixels = 0\n",
    "\n",
    "        return x\n",
    "\n",
    "    def dynamic_output_size_helper(self, x):\n",
    "        if self.adding_x_pixels != 0:\n",
    "            x = x[:, :, :-self.adding_x_pixels, :]\n",
    "        if self.adding_y_pixels != 0:\n",
    "            x = x[:,  :, :, :-self.adding_y_pixels]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"AE LAYER SIZE DEBUG\")\n",
    "            print(\"Encoder in\", x.size())\n",
    "\n",
    "        if self.protection:\n",
    "            x = nn.functional.pad(x, (self.dynamic_input_multiple, self.dynamic_input_multiple, self.dynamic_input_multiple, self.dynamic_input_multiple), mode='constant', value=0)\n",
    "            if self.encoder_debug == 1:\n",
    "                print(\"Encoder Protective Pad out\", x.size())\n",
    "\n",
    "        if self.dynamic:\n",
    "            x = self.dynamic_input_size_helper(x)\n",
    "            if self.encoder_debug == 1:\n",
    "                print(\"Encoder Dynamic Input Size Helper out\", x.size())\n",
    "\n",
    "        x = self.encoder_cnn(x)                           #Runs convoloutional encoder on x #!!! input data???\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Encoder CNN out\", x.size())\n",
    "    \n",
    "        self.pre_flattened_size = x.size()[1:]         # Saves the size of the output of the conv encoder for use in the unflatten layer\n",
    "        print(\"Pre flattened size: \", self.pre_flattened_size)\n",
    "\n",
    "        self.set_lin_layers(self.pre_flattened_size[0], self.pre_flattened_size[1], self.pre_flattened_size[2])            #Sets the size of the linear layers based on the output of the conv encoder\n",
    "\n",
    "        x = self.flatten(x)                               #Runs flatten  on output of conv encoder #!!! what is flatten?\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Encoder Flatten out\", x.size())\n",
    "\n",
    "\n",
    "        x = self.encoder_lin(x)                           #Runs linear encoder on flattened output \n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Encoder Lin out\", x.size(),\"\\n\")     \n",
    "        \n",
    "        if self.encoder_debug == 1:            \n",
    "            print(\"DECODER LAYER SIZE DEBUG\")\n",
    "            print(\"Decoder in\", x.size())   \n",
    "\n",
    "        x = self.decoder_lin(x)       #Runs linear decoder on x #!!! is x input data? where does it come from??\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Decoder Lin out\", x.size()) \n",
    "        \n",
    "        unflatten = nn.Unflatten(dim=1, unflattened_size=self.pre_flattened_size)\n",
    "        x = unflatten(x)         #Runs unflatten on output of linear decoder #!!! what is unflatten?\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Decoder Unflatten out\", x.size())  \n",
    "        \n",
    "        x = self.decoder_conv(x)      #Runs convoloutional decoder on output of unflatten\n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Decoder CNN out\", x.size())            \n",
    "\n",
    "        if self.dynamic:\n",
    "            x = self.dynamic_output_size_helper(x)\n",
    "            if self.encoder_debug == 1:\n",
    "                print(\"Decoder Dynamic Output Size Helper out\", x.size())\n",
    "\n",
    "        if self.protection:\n",
    "            # cropping self.dynamic_input_multiple pixels from each edge of the output\n",
    "            x = x[:, :, self.dynamic_input_multiple:-self.dynamic_input_multiple, self.dynamic_input_multiple:-self.dynamic_input_multiple]\n",
    "            if self.encoder_debug == 1:\n",
    "                print(\"Decoder Protective Pad out\", x.size())   \n",
    "\n",
    "        x = torch.sigmoid(x)  \n",
    "        if self.encoder_debug == 1:\n",
    "            print(\"Decoder out\", x.size(),\"\\n\")\n",
    "            self.encoder_debug = 0     \n",
    "\n",
    "        return x                      #Retuns the final output\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "encoder = Autoencoder(100, True)\n",
    "with torch.no_grad(): # No need to track the gradients\n",
    "    \n",
    "    # Create dummy input tensor\n",
    "    enc_input_tensor = torch.randn(1, 1, 1, 3) \n",
    "\n",
    "    # Generate network summary and then convert to string\n",
    "    model_stats = summary(encoder, input_data=enc_input_tensor, device='cpu', verbose=0)\n",
    "    summary_str = str(model_stats)             \n",
    "    print(summary_str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
