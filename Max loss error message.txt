
Training Initiated
Epochs:   0%| | 0/16 [00:00
Traceback (most recent call last):
  File "a:\Users\Ada\GitHub\DeepClean_Repo\DC3D_V3\DC3D_V3_Trainer 2.py", line 1008, in <module>
    train_loss=train_epoch_den(
  File "a:\Users\Ada\GitHub\DeepClean_Repo\DC3D_V3\DC3D_V3_Trainer 2.py", line 608, in train_epoch_den
    loss.backward() # Compute the gradients
  File "C:\Users\Ada\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\Ada\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\autograd\__init__.py", line 173, in backward 
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.DoubleTensor 
[10, 1, 128, 88]] is at version 1381; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
PS A:\Users\Ada\GitHub\DeepClean_Repo>



