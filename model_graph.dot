digraph {
	graph [size="24.15,24.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1819764916768 [label="
 (10, 1, 128, 88)" fillcolor=darkolivegreen1]
	1819764796288 [label=SigmoidBackward0]
	1819764796384 -> 1819764796288
	1819764796384 [label=ConvolutionBackward0]
	1819764795184 -> 1819764796384
	1819764795184 [label=ReluBackward0]
	1819764796528 -> 1819764795184
	1819764796528 [label=NativeBatchNormBackward0]
	1819764796624 -> 1819764796528
	1819764796624 [label=ConvolutionBackward0]
	1819764796816 -> 1819764796624
	1819764796816 [label=ReluBackward0]
	1819764797008 -> 1819764796816
	1819764797008 [label=NativeBatchNormBackward0]
	1819764797104 -> 1819764797008
	1819764797104 [label=ConvolutionBackward0]
	1819764797296 -> 1819764797104
	1819764797296 [label=ViewBackward0]
	1819764797392 -> 1819764797296
	1819764797392 [label=ReluBackward0]
	1819764932816 -> 1819764797392
	1819764932816 [label=AddmmBackward0]
	1819764932912 -> 1819764932816
	1819599166976 [label="1.decoder_lin.2.bias
 (4800)" fillcolor=lightblue]
	1819599166976 -> 1819764932912
	1819764932912 [label=AccumulateGrad]
	1819764932864 -> 1819764932816
	1819764932864 [label=ReluBackward0]
	1819764933104 -> 1819764932864
	1819764933104 [label=AddmmBackward0]
	1819764933296 -> 1819764933104
	1819599166816 [label="1.decoder_lin.0.bias
 (128)" fillcolor=lightblue]
	1819599166816 -> 1819764933296
	1819764933296 [label=AccumulateGrad]
	1819764933248 -> 1819764933104
	1819764933248 [label=AddmmBackward0]
	1819764933440 -> 1819764933248
	1819599166656 [label="0.encoder_lin.2.bias
 (10)" fillcolor=lightblue]
	1819599166656 -> 1819764933440
	1819764933440 [label=AccumulateGrad]
	1819764933488 -> 1819764933248
	1819764933488 [label=ReluBackward0]
	1819764933632 -> 1819764933488
	1819764933632 [label=AddmmBackward0]
	1819764933824 -> 1819764933632
	1819599166496 [label="0.encoder_lin.0.bias
 (128)" fillcolor=lightblue]
	1819599166496 -> 1819764933824
	1819764933824 [label=AccumulateGrad]
	1819764933776 -> 1819764933632
	1819764933776 [label=ReshapeAliasBackward0]
	1819764933968 -> 1819764933776
	1819764933968 [label=ReluBackward0]
	1819764934160 -> 1819764933968
	1819764934160 [label=ConvolutionBackward0]
	1819764934256 -> 1819764934160
	1819764934256 [label=ReluBackward0]
	1819764934448 -> 1819764934256
	1819764934448 [label=NativeBatchNormBackward0]
	1819764934544 -> 1819764934448
	1819764934544 [label=ConvolutionBackward0]
	1819764934736 -> 1819764934544
	1819764934736 [label=ReluBackward0]
	1819764934928 -> 1819764934736
	1819764934928 [label=ConvolutionBackward0]
	1819764934976 -> 1819764934928
	1819599165296 [label="0.encoder_cnn.0.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	1819599165296 -> 1819764934976
	1819764934976 [label=AccumulateGrad]
	1819764934832 -> 1819764934928
	1819599165376 [label="0.encoder_cnn.0.bias
 (8)" fillcolor=lightblue]
	1819599165376 -> 1819764934832
	1819764934832 [label=AccumulateGrad]
	1819764934688 -> 1819764934544
	1819599165536 [label="0.encoder_cnn.2.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	1819599165536 -> 1819764934688
	1819764934688 [label=AccumulateGrad]
	1819764934640 -> 1819764934544
	1819599165616 [label="0.encoder_cnn.2.bias
 (16)" fillcolor=lightblue]
	1819599165616 -> 1819764934640
	1819764934640 [label=AccumulateGrad]
	1819764934496 -> 1819764934448
	1819599165696 [label="0.encoder_cnn.3.weight
 (16)" fillcolor=lightblue]
	1819599165696 -> 1819764934496
	1819764934496 [label=AccumulateGrad]
	1819764934352 -> 1819764934448
	1819599165776 [label="0.encoder_cnn.3.bias
 (16)" fillcolor=lightblue]
	1819599165776 -> 1819764934352
	1819764934352 [label=AccumulateGrad]
	1819764934208 -> 1819764934160
	1819599166256 [label="0.encoder_cnn.5.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	1819599166256 -> 1819764934208
	1819764934208 [label=AccumulateGrad]
	1819764934064 -> 1819764934160
	1819599166336 [label="0.encoder_cnn.5.bias
 (32)" fillcolor=lightblue]
	1819599166336 -> 1819764934064
	1819764934064 [label=AccumulateGrad]
	1819764933728 -> 1819764933632
	1819764933728 [label=TBackward0]
	1819764934304 -> 1819764933728
	1819599166416 [label="0.encoder_lin.0.weight
 (128, 4800)" fillcolor=lightblue]
	1819599166416 -> 1819764934304
	1819764934304 [label=AccumulateGrad]
	1819764933536 -> 1819764933248
	1819764933536 [label=TBackward0]
	1819764934112 -> 1819764933536
	1819599166576 [label="0.encoder_lin.2.weight
 (10, 128)" fillcolor=lightblue]
	1819599166576 -> 1819764934112
	1819764934112 [label=AccumulateGrad]
	1819764933200 -> 1819764933104
	1819764933200 [label=TBackward0]
	1819764934400 -> 1819764933200
	1819599166736 [label="1.decoder_lin.0.weight
 (128, 10)" fillcolor=lightblue]
	1819599166736 -> 1819764934400
	1819764934400 [label=AccumulateGrad]
	1819764932672 -> 1819764932816
	1819764932672 [label=TBackward0]
	1819764933872 -> 1819764932672
	1819599166896 [label="1.decoder_lin.2.weight
 (4800, 128)" fillcolor=lightblue]
	1819599166896 -> 1819764933872
	1819764933872 [label=AccumulateGrad]
	1819764797248 -> 1819764797104
	1819599167216 [label="1.decoder_conv.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	1819599167216 -> 1819764797248
	1819764797248 [label=AccumulateGrad]
	1819764797200 -> 1819764797104
	1819599167296 [label="1.decoder_conv.0.bias
 (16)" fillcolor=lightblue]
	1819599167296 -> 1819764797200
	1819764797200 [label=AccumulateGrad]
	1819764797056 -> 1819764797008
	1819599167376 [label="1.decoder_conv.1.weight
 (16)" fillcolor=lightblue]
	1819599167376 -> 1819764797056
	1819764797056 [label=AccumulateGrad]
	1819764796912 -> 1819764797008
	1819599253568 [label="1.decoder_conv.1.bias
 (16)" fillcolor=lightblue]
	1819599253568 -> 1819764796912
	1819764796912 [label=AccumulateGrad]
	1819764796768 -> 1819764796624
	1819599253968 [label="1.decoder_conv.3.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	1819599253968 -> 1819764796768
	1819764796768 [label=AccumulateGrad]
	1819764796720 -> 1819764796624
	1819599254048 [label="1.decoder_conv.3.bias
 (8)" fillcolor=lightblue]
	1819599254048 -> 1819764796720
	1819764796720 [label=AccumulateGrad]
	1819764796576 -> 1819764796528
	1819599254128 [label="1.decoder_conv.4.weight
 (8)" fillcolor=lightblue]
	1819599254128 -> 1819764796576
	1819764796576 [label=AccumulateGrad]
	1819764796432 -> 1819764796528
	1819599254208 [label="1.decoder_conv.4.bias
 (8)" fillcolor=lightblue]
	1819599254208 -> 1819764796432
	1819764796432 [label=AccumulateGrad]
	1819764794320 -> 1819764796384
	1819599254608 [label="1.decoder_conv.6.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	1819599254608 -> 1819764794320
	1819764794320 [label=AccumulateGrad]
	1819764794416 -> 1819764796384
	1819599254688 [label="1.decoder_conv.6.bias
 (1)" fillcolor=lightblue]
	1819599254688 -> 1819764794416
	1819764794416 [label=AccumulateGrad]
	1819764796288 -> 1819764916768
}
