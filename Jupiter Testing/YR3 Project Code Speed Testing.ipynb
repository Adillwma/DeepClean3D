{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df7fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit                                   # Used in timer_function to test code execution times\n",
    "import numpy as np                              # Numerical processing library\n",
    "import matplotlib.pyplot as plt                 # Matplotlib plotting library\n",
    "\n",
    "###Helper functions \n",
    "def drag_race(number, repeats, functions, args_lists, sig_figs=3, share_args=False):\n",
    "    \"\"\"\n",
    "    Runs timeit.repeat on each function in the the input list 'functions' a specified number of times and \n",
    "    prints the minimum runtime for each func\n",
    "    \n",
    "    # Arguments:\n",
    "    number:     Number of times to run the functions per repeat.\n",
    "    repeats:    Number of times to time the function (each time function is timed it is run 'number' times).\n",
    "    functions:  The functions to be timed, in format [function_name_1, function_name_2].\n",
    "    args_lists: Arguments to pass to the functions using format [[F1-arg1, F1-arg2], [F2-arg1, F2-arg2, F2-arg3]] Unless all \n",
    "                functions take same arguments in which case pass [[shared_arg1, shared_arg2]] and then also set share_args=True.\n",
    "    sig_figs:   Sets the number of significant figures for the printed results readout [Default=3].\n",
    "    share_args: If all functions share the same argumnets then passing share_args=True allows user to only input them once and they are used for all fucntions [Default=False].\n",
    "    \n",
    "    # Returns:\n",
    "    No values are returned instead function automatically prints statment with function names and min runtimes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if share_args == True:\n",
    "        args_lists = args_lists * len(functions)  # If share args is used the single set of arguments is copied for the numebr of function requiring them\n",
    "        \n",
    "    for i, function in enumerate(functions):\n",
    "        \n",
    "        run_times = timeit.repeat(lambda: function(*args_lists[i]), number=number, repeat=repeats)\n",
    "        min_time = min(run_times)/number\n",
    "\n",
    "        print(\"\\nFunction: {}\\nRuntime: {} ms (minimum result over {} runs)\".format(function.__name__, round(min_time*1000, sig_figs), repeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d44943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% - Dependencies\n",
    "# External Libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import importlib.util\n",
    "import re\n",
    "\n",
    "# Enable for dynamic plots\n",
    "#%matplotlib notebook\n",
    "# Enable for still plots\n",
    "%matplotlib inline \n",
    "\n",
    "#%% - functions\n",
    "# Import and prepare Autoencoder model\n",
    "def setup_encoder_decoder(latent_dim,pretrained_model_path, AE_file_folder_path):\n",
    "    #from DC3D_Autoencoder_V1 import Encoder, Decoder   # make this programatic from the model folder as it also contains the backup AE file\n",
    "\n",
    "    def import_encoder_decoder(folder_path):\n",
    "        module_name_pattern = r\"DC3D_Autoencoder_V\\w+\\.py\"\n",
    "        module_path_pattern = os.path.join(folder_path, module_name_pattern)\n",
    "\n",
    "        matching_files = [file for file in os.listdir(folder_path) if re.match(module_name_pattern, file)]\n",
    "        if not matching_files:\n",
    "            raise ImportError(f\"No DC3D_Autoencoder module found in {folder_path}\\n\")\n",
    "\n",
    "        module_name = matching_files[0][:-3]\n",
    "        module_path = os.path.join(folder_path, f\"{module_name}.py\")\n",
    "        print(f\"Loaded {module_name}\\n\")\n",
    "        spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        return module.Encoder, module.Decoder\n",
    "    \n",
    "    Encoder, Decoder = import_encoder_decoder(AE_file_folder_path)\n",
    "    encoder = Encoder(encoded_space_dim=latent_dim, fc2_input_dim=128, encoder_debug=False, record_activity=False)\n",
    "    decoder = Decoder(encoded_space_dim=latent_dim, fc2_input_dim=128, decoder_debug=False, record_activity=False)\n",
    "    encoder.double()   \n",
    "    decoder.double()\n",
    "\n",
    "    # load the full state dictionary into memory\n",
    "    full_state_dict = torch.load(pretrained_model_path)\n",
    "\n",
    "    # load the state dictionaries into the models\n",
    "    encoder.load_state_dict(full_state_dict['encoder_state_dict'])\n",
    "    decoder.load_state_dict(full_state_dict['decoder_state_dict'])\n",
    "\n",
    "    encoder.eval()                                   #.eval() is a  switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and .eval() will do it for you. In addition, the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation\n",
    "    decoder.eval()    \n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "# New function to add n noise points to the 2d numpy array\n",
    "def add_noise_points_nonorm(input_image, noise_points=100, time_dimension=100):\n",
    "    image = input_image.copy()\n",
    "    \n",
    "    if noise_points > 0:\n",
    "        #Find dimensions of input image \n",
    "        x_dim = image.shape[0]\n",
    "        y_dim = image.shape[1]\n",
    "\n",
    "        #Create a list of random x and y coordinates\n",
    "        x_coords = np.random.randint(0, x_dim, noise_points)\n",
    "        y_coords = np.random.randint(0, y_dim, noise_points)\n",
    "\n",
    "        # Iterate through noise_points number of random pixels to noise\n",
    "        for i in range(noise_points):\n",
    "\n",
    "            # Add a random number between 0 and time_dimension to the pixel \n",
    "            image[x_coords[i], y_coords[i]] = np.random.uniform(0, time_dimension)\n",
    "    return image\n",
    "\n",
    "def image_loader(input_image_path, noise_points, time_dimension=100):\n",
    "    ### Load image from path \n",
    "    input_image = np.load(input_image_path)\n",
    "    \n",
    "    # Add noise if noise_points is greater than 1\n",
    "    noisy_image = add_noise_points_nonorm(input_image, noise_points, time_dimension)\n",
    "    \n",
    "    # Turn input image into tensor and add two extra dimesnions to start of array so shape goes from (x,y) to (1,1,x,y) to represent batch and channel dims\n",
    "    noisy_image_tensor = torch.tensor(noisy_image)\n",
    "    noisy_image_tensor.double()  \n",
    "    \n",
    "    return input_image, noisy_image_tensor\n",
    "\n",
    "def custom_normalisation(data, reconstruction_threshold, time_dimension=100):\n",
    "    data = ((data / time_dimension) / (1/(1-reconstruction_threshold))) + reconstruction_threshold\n",
    "    for row in data:   ###REPLACE USING NP.WHERE\n",
    "        for i, ipt in enumerate(row):\n",
    "            if ipt == reconstruction_threshold:\n",
    "                row[i] = 0\n",
    "    return data\n",
    "\n",
    "def custom_renormalisation(data, reconstruction_threshold, time_dimension=100):\n",
    "    data = np.where(data > reconstruction_threshold, ((data - reconstruction_threshold)*(1/(1-reconstruction_threshold)))*(time_dimension), 0)\n",
    "    return data\n",
    "\n",
    "def build_3d(data, time_dimension=100):\n",
    "    # Apply the processing functions to the data\n",
    "    shape = data.shape\n",
    "    processed_data = np.zeros((shape[0], shape[1], time_dimension))\n",
    "\n",
    "    i, j = np.nonzero(data)           # Compute the indices for the non-zero elements of data in the third dimension of array_3D\n",
    "    k = data[i, j].astype(int)        # Convert the values to integers\n",
    "    processed_data[i, j, k-1] = 1     # array_3D is now a 3D numpy array of size n by m by time_dimension_max, with the non-zero values from the original 2D array set to 1 in the appropriate location \n",
    "    return(processed_data)\n",
    "\n",
    "def multi_3d_plotting(input_image, noised_image, rec_image, masked_rec_image, time_dimension=100, show_2d_projection=True):\n",
    "    # Create a 3D plot with two subplots\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    titles = ['Input Image', 'Noised Image', 'DC3D Rec Image', 'Masked DC3D Rec Img']\n",
    "    \n",
    "    # Loop through both input_image and rec_image and create a 2d subplot for each\n",
    "    for i, image in enumerate([input_image, noised_image, rec_image, masked_rec_image]):    \n",
    "        ax = fig.add_subplot(2, 4, i+1)\n",
    "        ax.imshow(image)\n",
    "        ax.set_xlabel('X (px)')\n",
    "        ax.set_ylabel('Y (px)')\n",
    "        # Set the title of the subplot\n",
    "        ax.set_title(titles[i])\n",
    "        \n",
    "    # Loop through both input_image and rec_image and create a 3d subplot for each\n",
    "    for i, image in enumerate([input_image, noised_image, rec_image, masked_rec_image]):\n",
    "        ax = fig.add_subplot(2, 4, 4 + i+1, projection='3d')\n",
    "\n",
    "        # Generate 3D image data\n",
    "        image_3d = build_3d(image, time_dimension)\n",
    "        \n",
    "        # Assume image is your 3D array of size n by m by t_max\n",
    "        n, m, t_max = image_3d.shape\n",
    "\n",
    "        # Create a meshgrid of x, y, and z values for the 3D plot\n",
    "        x, y, z = np.meshgrid(np.arange(m), np.arange(n), np.arange(t_max))\n",
    "\n",
    "        # Flatten the x, y, and z values and image for plotting\n",
    "        x = x.flatten()\n",
    "        y = y.flatten()\n",
    "        z = z.flatten()\n",
    "        image_3d = image_3d.flatten()\n",
    "\n",
    "        # Plot the 3D scatter plot with the non-zero values in the array set to 1\n",
    "        ax.scatter(z[image_3d == 1], x[image_3d == 1], y[image_3d == 1], c=z[image_3d == 1], cmap='viridis', marker='o', s=10, alpha=0.5, depthshade=False, linewidth=0)\n",
    "        #ax.set_xlabel('Time')\n",
    "        #ax.set_ylabel('X (px)')\n",
    "        #ax.set_zlabel('Y (px)')\n",
    "        ax.set_xlim(0, t_max)\n",
    "        ax.set_ylim(0, 88)\n",
    "        ax.set_zlim(0, 128)\n",
    "        \n",
    "        if show_2d_projection:\n",
    "            # plot the projected 2D data on the xy-plane\n",
    "            ax.scatter(np.zeros_like(z[image_3d == 1]), x[image_3d == 1], y[image_3d == 1], c='r', marker='o', s=10, alpha=0.3, depthshade=False, linewidth=0)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def multi_3d_plotting2(input_image, rec_image, time_dimension=100, show_2d_projection=True):\n",
    "    clrs=[\"r\", \"r\"]\n",
    "    # Create a 3D plot with two subplots\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    titles = ['Zero Noise Reconstruction']\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    # Loop through both input_image and rec_image and create a 3d subplot for each\n",
    "    for i, image in enumerate([input_image, rec_image]):\n",
    "        # Generate 3D image data\n",
    "        image_3d = build_3d(image, time_dimension)\n",
    "        \n",
    "        # Assume image is your 3D array of size n by m by t_max\n",
    "        n, m, t_max = image_3d.shape\n",
    "\n",
    "        # Create a meshgrid of x, y, and z values for the 3D plot\n",
    "        x, y, z = np.meshgrid(np.arange(m), np.arange(n), np.arange(t_max))\n",
    "\n",
    "        # Flatten the x, y, and z values and image for plotting\n",
    "        x = x.flatten()\n",
    "        y = y.flatten()\n",
    "        z = z.flatten()\n",
    "        image_3d = image_3d.flatten()\n",
    "        if i == 0 :\n",
    "            col = \"r\"\n",
    "        else:\n",
    "            col = z[image_3d == 1]\n",
    "        # Plot the 3D scatter plot with the non-zero values in the array set to 1\n",
    "        ax.scatter(z[image_3d == 1], x[image_3d == 1], y[image_3d == 1], c=col, marker='o', s=10, alpha=0.5, depthshade=False, linewidth=0)\n",
    "    \n",
    "    ax.set_xlabel('t')\n",
    "    ax.set_ylabel('x')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_xlim(0, t_max)\n",
    "    ax.set_ylim(0, 88)\n",
    "    ax.set_zlim(0, 128)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "# Masking technique\n",
    "def masking_recovery(input_image, recovered_image, print_result=True):\n",
    "    raw_input_image = input_image.clone()\n",
    "    net_recovered_image = recovered_image.copy()\n",
    "    #Evaluate usefullness \n",
    "    # count the number of non-zero values\n",
    "    masking_pixels = np.count_nonzero(net_recovered_image)\n",
    "    image_shape = net_recovered_image.shape\n",
    "    total_pixels = image_shape[0] * image_shape[1] * time_dimension\n",
    "    # print the count\n",
    "    if print_result:\n",
    "        print(f\"Total number of pixels in the timescan: {format(total_pixels, ',')}\\nNumber of pixels returned by the masking: {format(masking_pixels, ',')}\\nNumber of pixels removed from reconstruction by masking: {format(total_pixels - masking_pixels, ',')}\")\n",
    "\n",
    "    # use np.where and boolean indexing to update values in a\n",
    "    mask_indexs = np.where(net_recovered_image != 0)\n",
    "    net_recovered_image[mask_indexs] = raw_input_image[mask_indexs]\n",
    "    result = net_recovered_image\n",
    "    return result\n",
    "                \n",
    "                \n",
    "#Following function runs the autoencoder on the input data\n",
    "def deepclean3(input_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension=100):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        norm_image = custom_normalisation(input_image_tensor, reconstruction_threshold, time_dimension)\n",
    "        image_prepared = norm_image.unsqueeze(0).unsqueeze(0)   #Adds two extra dimesnions to start of array so shape goes from (x,y) to (1,1,x,y) to represent batch and channel dims\n",
    "        rec_image = decoder(encoder(image_prepared))                         #Creates a recovered image (denoised image), by running a noisy image through the encoder and then the output of that through the decoder.\n",
    "        rec = rec_image.squeeze().numpy()\n",
    "        rec_image_renorm = custom_renormalisation(rec, reconstruction_threshold, time_dimension)\n",
    "    return rec_image_renorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad07b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DC3D_Autoencoder_V1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#User Inputs\n",
    "input_image_path = \"N:\\Yr 3 Project Datasets\\Dataset 24_X10ks\\Data\\Flat SimpleX-128x88-1 Crosses, No3767.npy\"\n",
    "time_dimension = 100\n",
    "noise_points = 1000\n",
    "show_2d_projection = False\n",
    "\n",
    "#AE Settings\n",
    "reconstruction_threshold = 0.5\n",
    "latent_dim = 10\n",
    "model_name = \"D25 50K lr0001 weightedMSE0point99-1 DAE np200\"\n",
    "\n",
    "#Path settings\n",
    "pretrained_model_path = f\"N:\\\\Yr 3 Project Results\\\\{model_name} - Training Results\\\\{model_name} - Model + Optimiser State Dicts.pth\"\n",
    "AE_file_folder_path = f\"N:\\\\Yr 3 Project Results\\\\{model_name} - Training Results\\\\\"\n",
    "\n",
    "### Compute\n",
    "# Setup encoder and decoder and load models\n",
    "encoder, decoder = setup_encoder_decoder(latent_dim, pretrained_model_path, AE_file_folder_path)\n",
    "\n",
    "# Load input image\n",
    "if os.path.isdir(input_image_path): # If user provides folder path, selct a random .npy file from the input directory and add it to file path\n",
    "    input_image_path = os.path.join(input_image_path, np.random.choice(os.listdir(input_image_path)))\n",
    "    print(f\"Input path is a folder path, therfore selecting random image from folder.\\nImage selected is {input_image_path}\\nFor a specific image, pass in a file path not folder.\")\n",
    "\n",
    "#%% - Driver\n",
    "input_image, noisy_image_tensor = image_loader(input_image_path, noise_points, time_dimension)\n",
    "\n",
    "\n",
    "#T1\n",
    "def direct_func(noisy_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension):\n",
    "    recovered_image = deepclean3(noisy_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension)\n",
    "    pass\n",
    "\n",
    "#T2\n",
    "def masking_func(noisy_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension):\n",
    "    recovered_image = deepclean3(noisy_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension)\n",
    "    masked_rec_image = masking_recovery(noisy_image_tensor, recovered_image, print_result=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "362dc236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function: direct_func\n",
      "Runtime: 108.94 ms (minimum result over 1000 runs)\n",
      "\n",
      "Function: masking_func\n",
      "Runtime: 110.289 ms (minimum result over 1000 runs)\n"
     ]
    }
   ],
   "source": [
    "# functions = [direct_func, masking_func]\n",
    "args_list = [[noisy_image_tensor, reconstruction_threshold, encoder, decoder, time_dimension]]\n",
    "\n",
    "\n",
    "drag_race(number=1, repeats=1000, functions=functions, args_lists=args_list, sig_figs=3, share_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a48f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
