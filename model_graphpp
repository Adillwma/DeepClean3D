digraph {
	graph [size="24.15,24.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2709163012560 [label="
 (10, 1, 128, 88)" fillcolor=darkolivegreen1]
	2709162896256 [label=SigmoidBackward0]
	2709162896352 -> 2709162896256
	2709162896352 [label=ConvolutionBackward0]
	2709162895152 -> 2709162896352
	2709162895152 [label=ReluBackward0]
	2709162896496 -> 2709162895152
	2709162896496 [label=NativeBatchNormBackward0]
	2709162896592 -> 2709162896496
	2709162896592 [label=ConvolutionBackward0]
	2709162896784 -> 2709162896592
	2709162896784 [label=ReluBackward0]
	2709162896976 -> 2709162896784
	2709162896976 [label=NativeBatchNormBackward0]
	2709162897072 -> 2709162896976
	2709162897072 [label=ConvolutionBackward0]
	2709162897264 -> 2709162897072
	2709162897264 [label=ViewBackward0]
	2709162897360 -> 2709162897264
	2709162897360 [label=ReluBackward0]
	2709163024592 -> 2709162897360
	2709163024592 [label=AddmmBackward0]
	2709163024688 -> 2709163024592
	2708997267104 [label="1.decoder_lin.2.bias
 (4800)" fillcolor=lightblue]
	2708997267104 -> 2709163024688
	2709163024688 [label=AccumulateGrad]
	2709163024640 -> 2709163024592
	2709163024640 [label=ReluBackward0]
	2709163024880 -> 2709163024640
	2709163024880 [label=AddmmBackward0]
	2709163025072 -> 2709163024880
	2708997266944 [label="1.decoder_lin.0.bias
 (128)" fillcolor=lightblue]
	2708997266944 -> 2709163025072
	2709163025072 [label=AccumulateGrad]
	2709163025024 -> 2709163024880
	2709163025024 [label=AddmmBackward0]
	2709163025216 -> 2709163025024
	2708997266784 [label="0.encoder_lin.2.bias
 (10)" fillcolor=lightblue]
	2708997266784 -> 2709163025216
	2709163025216 [label=AccumulateGrad]
	2709163025264 -> 2709163025024
	2709163025264 [label=ReluBackward0]
	2709163025408 -> 2709163025264
	2709163025408 [label=AddmmBackward0]
	2709163025600 -> 2709163025408
	2708997266624 [label="0.encoder_lin.0.bias
 (128)" fillcolor=lightblue]
	2708997266624 -> 2709163025600
	2709163025600 [label=AccumulateGrad]
	2709163025552 -> 2709163025408
	2709163025552 [label=ReshapeAliasBackward0]
	2709163025744 -> 2709163025552
	2709163025744 [label=ReluBackward0]
	2709163025936 -> 2709163025744
	2709163025936 [label=ConvolutionBackward0]
	2709163026032 -> 2709163025936
	2709163026032 [label=ReluBackward0]
	2709163026224 -> 2709163026032
	2709163026224 [label=NativeBatchNormBackward0]
	2709163026320 -> 2709163026224
	2709163026320 [label=ConvolutionBackward0]
	2709163026512 -> 2709163026320
	2709163026512 [label=ReluBackward0]
	2709163026704 -> 2709163026512
	2709163026704 [label=ConvolutionBackward0]
	2709163026752 -> 2709163026704
	2708997265424 [label="0.encoder_cnn.0.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	2708997265424 -> 2709163026752
	2709163026752 [label=AccumulateGrad]
	2709163026608 -> 2709163026704
	2708997265504 [label="0.encoder_cnn.0.bias
 (8)" fillcolor=lightblue]
	2708997265504 -> 2709163026608
	2709163026608 [label=AccumulateGrad]
	2709163026464 -> 2709163026320
	2708997265664 [label="0.encoder_cnn.2.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2708997265664 -> 2709163026464
	2709163026464 [label=AccumulateGrad]
	2709163026416 -> 2709163026320
	2708997265744 [label="0.encoder_cnn.2.bias
 (16)" fillcolor=lightblue]
	2708997265744 -> 2709163026416
	2709163026416 [label=AccumulateGrad]
	2709163026272 -> 2709163026224
	2708997265824 [label="0.encoder_cnn.3.weight
 (16)" fillcolor=lightblue]
	2708997265824 -> 2709163026272
	2709163026272 [label=AccumulateGrad]
	2709163026128 -> 2709163026224
	2708997265904 [label="0.encoder_cnn.3.bias
 (16)" fillcolor=lightblue]
	2708997265904 -> 2709163026128
	2709163026128 [label=AccumulateGrad]
	2709163025984 -> 2709163025936
	2708997266384 [label="0.encoder_cnn.5.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2708997266384 -> 2709163025984
	2709163025984 [label=AccumulateGrad]
	2709163025840 -> 2709163025936
	2708997266464 [label="0.encoder_cnn.5.bias
 (32)" fillcolor=lightblue]
	2708997266464 -> 2709163025840
	2709163025840 [label=AccumulateGrad]
	2709163025504 -> 2709163025408
	2709163025504 [label=TBackward0]
	2709163026080 -> 2709163025504
	2708997266544 [label="0.encoder_lin.0.weight
 (128, 4800)" fillcolor=lightblue]
	2708997266544 -> 2709163026080
	2709163026080 [label=AccumulateGrad]
	2709163025312 -> 2709163025024
	2709163025312 [label=TBackward0]
	2709163025888 -> 2709163025312
	2708997266704 [label="0.encoder_lin.2.weight
 (10, 128)" fillcolor=lightblue]
	2708997266704 -> 2709163025888
	2709163025888 [label=AccumulateGrad]
	2709163024976 -> 2709163024880
	2709163024976 [label=TBackward0]
	2709163026176 -> 2709163024976
	2708997266864 [label="1.decoder_lin.0.weight
 (128, 10)" fillcolor=lightblue]
	2708997266864 -> 2709163026176
	2709163026176 [label=AccumulateGrad]
	2709163024448 -> 2709163024592
	2709163024448 [label=TBackward0]
	2709163025648 -> 2709163024448
	2708997267024 [label="1.decoder_lin.2.weight
 (4800, 128)" fillcolor=lightblue]
	2708997267024 -> 2709163025648
	2709163025648 [label=AccumulateGrad]
	2709162897216 -> 2709162897072
	2708997267344 [label="1.decoder_conv.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2708997267344 -> 2709162897216
	2709162897216 [label=AccumulateGrad]
	2709162897168 -> 2709162897072
	2708997345344 [label="1.decoder_conv.0.bias
 (16)" fillcolor=lightblue]
	2708997345344 -> 2709162897168
	2709162897168 [label=AccumulateGrad]
	2709162897024 -> 2709162896976
	2708997345424 [label="1.decoder_conv.1.weight
 (16)" fillcolor=lightblue]
	2708997345424 -> 2709162897024
	2709162897024 [label=AccumulateGrad]
	2709162896880 -> 2709162896976
	2708997345504 [label="1.decoder_conv.1.bias
 (16)" fillcolor=lightblue]
	2708997345504 -> 2709162896880
	2709162896880 [label=AccumulateGrad]
	2709162896736 -> 2709162896592
	2708997345904 [label="1.decoder_conv.3.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	2708997345904 -> 2709162896736
	2709162896736 [label=AccumulateGrad]
	2709162896688 -> 2709162896592
	2708997345984 [label="1.decoder_conv.3.bias
 (8)" fillcolor=lightblue]
	2708997345984 -> 2709162896688
	2709162896688 [label=AccumulateGrad]
	2709162896544 -> 2709162896496
	2708997346064 [label="1.decoder_conv.4.weight
 (8)" fillcolor=lightblue]
	2708997346064 -> 2709162896544
	2709162896544 [label=AccumulateGrad]
	2709162896400 -> 2709162896496
	2708997346144 [label="1.decoder_conv.4.bias
 (8)" fillcolor=lightblue]
	2708997346144 -> 2709162896400
	2709162896400 [label=AccumulateGrad]
	2709162894288 -> 2709162896352
	2708997346544 [label="1.decoder_conv.6.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	2708997346544 -> 2709162894288
	2709162894288 [label=AccumulateGrad]
	2709162894384 -> 2709162896352
	2708997346624 [label="1.decoder_conv.6.bias
 (1)" fillcolor=lightblue]
	2708997346624 -> 2709162894384
	2709162894384 [label=AccumulateGrad]
	2709162896256 -> 2709163012560
}
